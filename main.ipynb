{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import snntorch as snn\n",
    "import snntorch.functional as SF\n",
    "from snntorch import spikeplot as splt\n",
    "from CNC_Machining.utils import data_loader_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from snntorch import surrogate\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "## if you're on M1 or M2 GPU:\n",
    "# device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CNC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "machines = [\"M01\", \"M02\", \"M03\"]\n",
    "process_names = [\n",
    "    \"OP00\",\n",
    "    \"OP01\",\n",
    "    \"OP02\",\n",
    "    \"OP03\",\n",
    "    \"OP04\",\n",
    "    \"OP05\",\n",
    "    \"OP06\",\n",
    "    \"OP07\",\n",
    "    \"OP08\",\n",
    "    \"OP09\",\n",
    "    \"OP10\",\n",
    "    \"OP11\",\n",
    "    \"OP12\",\n",
    "    \"OP13\",\n",
    "    \"OP14\",\n",
    "]\n",
    "labels = [\"good\", \"bad\"]\n",
    "path_to_dataset = \"./CNC_Machining/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laoding files from ./CNC_Machining/data/M01/OP00/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP00/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP00/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP00/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP00/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP00/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP01/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP01/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP01/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP01/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP01/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP01/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP02/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP02/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP02/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP02/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP02/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP02/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP03/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP03/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP03/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP03/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP03/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP03/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP04/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP04/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP04/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP04/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP04/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP04/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP05/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP05/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP05/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP05/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP05/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP05/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP06/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP06/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP06/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP06/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP06/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP06/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP07/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP07/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP07/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP07/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP07/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP07/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP08/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP08/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP08/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP08/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP08/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP08/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP09/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP09/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP09/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP09/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP09/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP09/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP10/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP10/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP10/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP10/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP10/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP10/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP11/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP11/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP11/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP11/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP11/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP11/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP12/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP12/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP12/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP12/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP12/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP12/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP13/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP13/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP13/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP13/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP13/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP13/bad... \n",
      "laoding files from ./CNC_Machining/data/M01/OP14/good... \n",
      "laoding files from ./CNC_Machining/data/M01/OP14/bad... \n",
      "laoding files from ./CNC_Machining/data/M02/OP14/good... \n",
      "laoding files from ./CNC_Machining/data/M02/OP14/bad... \n",
      "laoding files from ./CNC_Machining/data/M03/OP14/good... \n",
      "laoding files from ./CNC_Machining/data/M03/OP14/bad... \n"
     ]
    }
   ],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "class_count = {}\n",
    "\n",
    "# To avoid problems with firing rate we can rectify the signal and normalize the max\n",
    "\n",
    "dataset_max = 0\n",
    "for process_name in process_names:\n",
    "    for machine in machines:\n",
    "        for label in labels:\n",
    "            data_path = os.path.join(path_to_dataset, machine, process_name, label)\n",
    "            data_list, data_label = data_loader_utils.load_tool_research_data(\n",
    "                data_path, label=label\n",
    "            )\n",
    "\n",
    "            # Rectify\n",
    "            for data_i, data in enumerate(data_list):\n",
    "                data = data - np.mean(data, axis=0)\n",
    "                data[data < 0] = -data[data < 0]\n",
    "                data_list[data_i] = data\n",
    "                if np.max(np.abs(data)) > dataset_max:\n",
    "                    dataset_max = np.max(np.abs(data))\n",
    "\n",
    "            # concatenating\n",
    "            X_data.extend(data_list)\n",
    "            y_data.extend(data_label)\n",
    "\n",
    "n_recs = len(y_data)\n",
    "\n",
    "cnc_data_info_type = [\n",
    "    (\"machine\", \"U3\"),\n",
    "    (\"process\", \"U4\"),\n",
    "    (\"class\", \"U4\"),\n",
    "    (\"rec_date\", \"U10\"),\n",
    "    (\"idx\", \"U4\"),\n",
    "    (\"n_samples\", np.int32),\n",
    "]\n",
    "cnc_data_info = np.zeros(n_recs, dtype=cnc_data_info_type)\n",
    "\n",
    "for label_i, label in enumerate(y_data):\n",
    "    d_machine = label[:3]\n",
    "    d_process = label[13:17]\n",
    "    d_class = label[22:]\n",
    "    d_rec_date = label[4:12]\n",
    "    d_idx = label[18:21]\n",
    "    d_n_samples = len(X_data[label_i])\n",
    "    cnc_data_info[label_i] = np.array(\n",
    "        [(d_machine, d_process, d_class, d_rec_date, d_idx, d_n_samples)],\n",
    "        dtype=cnc_data_info_type,\n",
    "    )\n",
    "\n",
    "class_count[\"good\"] = sum(cnc_data_info[\"class\"] == \"good\")\n",
    "class_count[\"bad\"] = sum(cnc_data_info[\"class\"] == \"bad\")\n",
    "\n",
    "# Normalize data\n",
    "for data_i, data in enumerate(X_data):\n",
    "    X_data[data_i] = data / dataset_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file = path_to_dataset + \"M01/OP00/good/M01_Aug_2019_OP00_000.h5\"\n",
    "sample = data_loader_utils.datafile_read(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good': 1632, 'bad': 70}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count  # the dataset is unbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting a balanced dataset subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of matched recordings: 122\n"
     ]
    }
   ],
   "source": [
    "bad_subset_idx = cnc_data_info[\"class\"] == \"bad\"\n",
    "good_subset_idx = cnc_data_info[\"class\"] == \"good\"\n",
    "bad_subset = cnc_data_info[bad_subset_idx]\n",
    "dataset_idx = []\n",
    "\n",
    "n_axis = 2  # Choose the number of axis to represent\n",
    "train_batches_number = 2\n",
    "\n",
    "for bad_rec_i, bad_rec in enumerate(bad_subset):\n",
    "    good_match_idx = np.ones(n_recs, dtype=np.int32)\n",
    "    good_match_idx = good_match_idx * (bad_rec[\"machine\"] == cnc_data_info[\"machine\"])\n",
    "    good_match_idx = good_match_idx * (bad_rec[\"process\"] == cnc_data_info[\"process\"])\n",
    "    good_match_idx = good_match_idx * (bad_rec[\"rec_date\"] == cnc_data_info[\"rec_date\"])\n",
    "    good_match_idx = good_match_idx * (bad_rec[\"idx\"] == cnc_data_info[\"idx\"])\n",
    "    bad_match_idx = good_match_idx * bad_subset_idx\n",
    "    good_match_idx = good_match_idx * good_subset_idx\n",
    "    bad_match_idx = np.where(bad_match_idx == 1)[0]\n",
    "    good_match_idx = np.where(good_match_idx == 1)[0]\n",
    "    if good_match_idx.size > 0:\n",
    "        dataset_idx.append(good_match_idx[0])\n",
    "        dataset_idx.append(bad_match_idx[0])\n",
    "\n",
    "dataset_idx = np.array(dataset_idx)\n",
    "print(\"Total number of matched recordings: \" + str(len(dataset_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train single batch size: 42\n",
      "Test single batch size: 20\n"
     ]
    }
   ],
   "source": [
    "dataset_idx_train_good = []\n",
    "dataset_idx_train_bad = []\n",
    "dataset_idx_test_good = []\n",
    "dataset_idx_test_bad = []\n",
    "\n",
    "for idx in dataset_idx:\n",
    "    info = cnc_data_info[idx]\n",
    "\n",
    "    if info[\"machine\"] == \"M01\":\n",
    "        # Split the training set and the test set along idx\n",
    "        if info[\"idx\"] == \"000\":\n",
    "            if info[\"class\"] == \"good\":\n",
    "                dataset_idx_train_good.append(idx)\n",
    "            else:\n",
    "                dataset_idx_train_bad.append(idx)\n",
    "        else:\n",
    "            if info[\"class\"] == \"good\":\n",
    "                dataset_idx_test_good.append(idx)\n",
    "            else:\n",
    "                dataset_idx_test_bad.append(idx)\n",
    "\n",
    "train_idx = dataset_idx_train_good + dataset_idx_train_bad\n",
    "test_idx = dataset_idx_test_good + dataset_idx_test_bad\n",
    "\n",
    "train_batch_size = len(train_idx)\n",
    "test_batch_size = len(test_idx)\n",
    "print(\"Train single batch size: \" + str(train_batch_size))\n",
    "print(\"Test single batch size: \" + str(test_batch_size))\n",
    "# min_train_samples = min(cnc_data_info[train_idx][\"n_samples\"])\n",
    "# min_test_samples = min(cnc_data_info[test_idx][\"n_samples\"])\n",
    "min_train_samples = 1000\n",
    "min_test_samples = 1000\n",
    "\n",
    "# Create the actual train and test set by batching batch_i*n_samples*batch_size*3(IMUdim)\n",
    "# train_data = np.zeros([train_batch_size, min_train_samples,1,n_axis])\n",
    "# test_data = np.zeros([test_batch_size, min_test_samples,1,n_axis])\n",
    "train_data = np.zeros([min_train_samples, train_batch_size, n_axis])\n",
    "test_data = np.zeros([min_test_samples, test_batch_size, n_axis])\n",
    "\n",
    "train_labels = 1 * (cnc_data_info[train_idx][\"class\"] == \"bad\")\n",
    "test_labels = 1 * (cnc_data_info[test_idx][\"class\"] == \"bad\")\n",
    "\n",
    "for j, train_i in enumerate(train_idx):\n",
    "    # train_data[j,:,0] = X_data[train_i][:min_train_samples,:n_axis]\n",
    "    train_data[:, j] = X_data[train_i][:min_train_samples, :n_axis]\n",
    "\n",
    "for j, test_i in enumerate(test_idx):\n",
    "    # test_data[j,:,0] = X_data[test_i][:min_test_samples,:n_axis]\n",
    "    test_data[:, j] = X_data[test_i][:min_test_samples, :n_axis]\n",
    "\n",
    "train_data = torch.tensor(train_data, dtype=dtype)\n",
    "train_labels = F.one_hot(torch.tensor(train_labels)).float()\n",
    "test_data = torch.tensor(test_data, dtype=dtype)\n",
    "test_labels = F.one_hot(torch.tensor(test_labels)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('M01', 'OP01', 'good', 'Aug_2019', '000',  60416),\n",
       "       ('M01', 'OP01', 'good', 'Feb_2019', '000',  58800),\n",
       "       ('M01', 'OP02', 'good', 'Feb_2019', '000',  85200),\n",
       "       ('M01', 'OP03', 'good', 'Aug_2019', '000', 177152),\n",
       "       ('M01', 'OP04', 'good', 'Aug_2019', '000', 138240),\n",
       "       ('M01', 'OP04', 'good', 'Feb_2019', '000', 138000),\n",
       "       ('M01', 'OP05', 'good', 'Aug_2019', '000',  46080),\n",
       "       ('M01', 'OP05', 'good', 'Feb_2019', '000',  40800),\n",
       "       ('M01', 'OP05', 'good', 'Feb_2021', '000',  41984),\n",
       "       ('M01', 'OP06', 'good', 'Aug_2019', '000', 159744),\n",
       "       ('M01', 'OP06', 'good', 'Aug_2021', '000', 190464),\n",
       "       ('M01', 'OP07', 'good', 'Aug_2019', '000',  49152),\n",
       "       ('M01', 'OP07', 'good', 'Aug_2021', '000',  50176),\n",
       "       ('M01', 'OP07', 'good', 'Feb_2019', '000',  49200),\n",
       "       ('M01', 'OP08', 'good', 'Feb_2019', '000',  75600),\n",
       "       ('M01', 'OP09', 'good', 'Aug_2019', '000', 208896),\n",
       "       ('M01', 'OP10', 'good', 'Feb_2019', '000',  99600),\n",
       "       ('M01', 'OP11', 'good', 'Feb_2019', '000', 120000),\n",
       "       ('M01', 'OP11', 'good', 'Feb_2021', '000', 116736),\n",
       "       ('M01', 'OP12', 'good', 'Feb_2019', '000',  93600),\n",
       "       ('M01', 'OP14', 'good', 'Feb_2019', '000',  66000),\n",
       "       ('M01', 'OP01', 'bad', 'Aug_2019', '000',  38983),\n",
       "       ('M01', 'OP01', 'bad', 'Feb_2019', '000',  47081),\n",
       "       ('M01', 'OP02', 'bad', 'Feb_2019', '000',  71711),\n",
       "       ('M01', 'OP03', 'bad', 'Aug_2019', '000', 139653),\n",
       "       ('M01', 'OP04', 'bad', 'Aug_2019', '000',  67730),\n",
       "       ('M01', 'OP04', 'bad', 'Feb_2019', '000', 124781),\n",
       "       ('M01', 'OP05', 'bad', 'Aug_2019', '000',  26793),\n",
       "       ('M01', 'OP05', 'bad', 'Feb_2019', '000',  29831),\n",
       "       ('M01', 'OP05', 'bad', 'Feb_2021', '000',  30000),\n",
       "       ('M01', 'OP06', 'bad', 'Aug_2019', '000', 170156),\n",
       "       ('M01', 'OP06', 'bad', 'Aug_2021', '000', 176000),\n",
       "       ('M01', 'OP07', 'bad', 'Aug_2019', '000',  32199),\n",
       "       ('M01', 'OP07', 'bad', 'Aug_2021', '000',  42000),\n",
       "       ('M01', 'OP07', 'bad', 'Feb_2019', '000',  37511),\n",
       "       ('M01', 'OP08', 'bad', 'Feb_2019', '000',  64231),\n",
       "       ('M01', 'OP09', 'bad', 'Aug_2019', '000', 193906),\n",
       "       ('M01', 'OP10', 'bad', 'Feb_2019', '000',  83441),\n",
       "       ('M01', 'OP11', 'bad', 'Feb_2019', '000', 107161),\n",
       "       ('M01', 'OP11', 'bad', 'Feb_2021', '000',  90000),\n",
       "       ('M01', 'OP12', 'bad', 'Feb_2019', '000',  85411),\n",
       "       ('M01', 'OP14', 'bad', 'Feb_2019', '000',  52611)],\n",
       "      dtype=[('machine', '<U3'), ('process', '<U4'), ('class', '<U4'), ('rec_date', '<U10'), ('idx', '<U4'), ('n_samples', '<i4')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnc_data_info[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('M01', 'OP05', 'good', 'Feb_2019', '001',  40800),\n",
       "       ('M01', 'OP07', 'good', 'Aug_2021', '001',  51200),\n",
       "       ('M01', 'OP08', 'good', 'Feb_2019', '001',  75600),\n",
       "       ('M01', 'OP08', 'good', 'Feb_2019', '002',  73200),\n",
       "       ('M01', 'OP10', 'good', 'Feb_2019', '001',  98400),\n",
       "       ('M01', 'OP10', 'good', 'Feb_2019', '002',  92400),\n",
       "       ('M01', 'OP11', 'good', 'Feb_2019', '001', 116400),\n",
       "       ('M01', 'OP11', 'good', 'Feb_2019', '002', 120000),\n",
       "       ('M01', 'OP12', 'good', 'Feb_2019', '001',  91200),\n",
       "       ('M01', 'OP12', 'good', 'Feb_2019', '002',  96000),\n",
       "       ('M01', 'OP05', 'bad', 'Feb_2019', '001',  29621),\n",
       "       ('M01', 'OP07', 'bad', 'Aug_2021', '001',  46000),\n",
       "       ('M01', 'OP08', 'bad', 'Feb_2019', '001',  64181),\n",
       "       ('M01', 'OP08', 'bad', 'Feb_2019', '002',  64591),\n",
       "       ('M01', 'OP10', 'bad', 'Feb_2019', '001',  85831),\n",
       "       ('M01', 'OP10', 'bad', 'Feb_2019', '002',  86021),\n",
       "       ('M01', 'OP11', 'bad', 'Feb_2019', '001', 107551),\n",
       "       ('M01', 'OP11', 'bad', 'Feb_2019', '002', 107151),\n",
       "       ('M01', 'OP12', 'bad', 'Feb_2019', '001',  85231),\n",
       "       ('M01', 'OP12', 'bad', 'Feb_2019', '002',  84821)],\n",
       "      dtype=[('machine', '<U3'), ('process', '<U4'), ('class', '<U4'), ('rec_date', '<U10'), ('idx', '<U4'), ('n_samples', '<i4')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnc_data_info[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Neuron Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Plotting Settings\n",
    "def plot_cur_mem_spk(\n",
    "    cur,\n",
    "    mem,\n",
    "    spk,\n",
    "    thr_line=False,\n",
    "    vline=False,\n",
    "    title=False,\n",
    "    ylim_max1=1.25,\n",
    "    ylim_max2=1.25,\n",
    "):\n",
    "    # Generate Plots\n",
    "    fig, ax = plt.subplots(\n",
    "        3, figsize=(8, 6), sharex=True, gridspec_kw={\"height_ratios\": [1, 1, 0.4]}\n",
    "    )\n",
    "\n",
    "    # Plot input current\n",
    "    ax[0].plot(cur, c=\"tab:orange\")\n",
    "    ax[0].set_ylim([0, ylim_max1])\n",
    "    ax[0].set_xlim([0, 200])\n",
    "    ax[0].set_ylabel(\"Input Current ()\")\n",
    "    if title:\n",
    "        ax[0].set_title(title)\n",
    "\n",
    "    # Plot membrane potential\n",
    "    ax[1].plot(mem)\n",
    "    ax[1].set_ylim([0, ylim_max2])\n",
    "    ax[1].set_ylabel(\"Membrane Potential ()\")\n",
    "    if thr_line:\n",
    "        ax[1].axhline(\n",
    "            y=thr_line, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2\n",
    "        )\n",
    "    plt.xlabel(\"Time step\")\n",
    "\n",
    "    # Plot output spike using spikeplot\n",
    "    splt.raster(spk, ax[2], s=400, c=\"black\", marker=\"|\")\n",
    "    if vline:\n",
    "        ax[2].axvline(\n",
    "            x=vline,\n",
    "            ymin=0,\n",
    "            ymax=6.75,\n",
    "            alpha=0.15,\n",
    "            linestyle=\"dashed\",\n",
    "            c=\"black\",\n",
    "            linewidth=2,\n",
    "            zorder=0,\n",
    "            clip_on=False,\n",
    "        )\n",
    "    plt.ylabel(\"Output spikes\")\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_snn_spikes(spk_in, spk1_rec, spk2_rec, title):\n",
    "    # Generate Plots\n",
    "    fig, ax = plt.subplots(\n",
    "        3, figsize=(8, 7), sharex=True, gridspec_kw={\"height_ratios\": [1, 1, 0.4]}\n",
    "    )\n",
    "\n",
    "    # Plot input spikes\n",
    "    splt.raster(spk_in[:, 0], ax[0], s=0.03, c=\"black\")\n",
    "    ax[0].set_ylabel(\"Input Spikes\")\n",
    "    ax[0].set_title(title)\n",
    "\n",
    "    # Plot hidden layer spikes\n",
    "    splt.raster(spk1_rec.reshape(num_steps, -1), ax[1], s=0.05, c=\"black\")\n",
    "    ax[1].set_ylabel(\"Hidden Layer\")\n",
    "\n",
    "    # Plot output spikes\n",
    "    splt.raster(spk2_rec.reshape(num_steps, -1), ax[2], c=\"black\", marker=\"|\")\n",
    "    ax[2].set_ylabel(\"Output Spikes\")\n",
    "    ax[2].set_ylim([0, 10])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def dvs_animator(spike_data):\n",
    "    fig, ax = plt.subplots()\n",
    "    anim = splt.animator((spike_data[:, 0] + spike_data[:, 1]), fig, ax)\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_test = 0.8\n",
    "threshold_test = 0.1\n",
    "lif = snn.Leaky(beta=beta_test, threshold=threshold_test)  # LIF neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup inputs\n",
    "num_steps = 200  # number of time-steps to simulate\n",
    "\n",
    "x = train_data[:, 0, :1].sum(1)\n",
    "\n",
    "# Small step current input\n",
    "# w = 0.15, # then run 0.20, 0.21\n",
    "# x = torch.cat((torch.zeros(10), torch.ones(190)*w), 0)\n",
    "mem = torch.zeros(1)\n",
    "spk = torch.zeros(1)\n",
    "\n",
    "mem_rec = []\n",
    "spk_rec = []\n",
    "\n",
    "# neuron simulation\n",
    "for step in range(num_steps):\n",
    "    spk, mem = lif(x[step], mem)\n",
    "    mem_rec.append(mem)\n",
    "    spk_rec.append(spk)\n",
    "\n",
    "# convert lists to tensors\n",
    "mem_rec = torch.stack(mem_rec)\n",
    "spk_rec = torch.stack(spk_rec)\n",
    "\n",
    "plot_cur_mem_spk(\n",
    "    x,\n",
    "    mem_rec,\n",
    "    spk_rec,\n",
    "    thr_line=threshold_test,\n",
    "    ylim_max1=1.0,\n",
    "    title=\"snn.Leaky Neuron Model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a simple SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "num_inputs = n_axis\n",
    "num_hidden = 10\n",
    "num_outputs = 2\n",
    "\n",
    "# Temporal Dynamics\n",
    "num_steps = min_train_samples\n",
    "hid_beta = np.linspace(0.4, 0.8, num_hidden)\n",
    "hid_beta = torch.tensor(hid_beta, dtype=dtype)\n",
    "out_beta = 0.95\n",
    "hid_thresh = 0.1\n",
    "thresh = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to measure accuracy\n",
    "def measure_accuracy(spk_rec, targets):\n",
    "    with torch.no_grad():\n",
    "        running_length = 0\n",
    "        running_accuracy = 0\n",
    "\n",
    "        spike_count = spk_rec.sum(0)\n",
    "        _, max_spike = spike_count.max(1)\n",
    "\n",
    "        # correct classes for one batch\n",
    "        num_correct = (max_spike == torch.argmax(targets, dim=1)).sum()\n",
    "\n",
    "        # total accuracy\n",
    "        running_length += len(targets)\n",
    "        running_accuracy += num_correct\n",
    "\n",
    "        accuracy = running_accuracy / running_length\n",
    "\n",
    "        return accuracy.item()\n",
    "\n",
    "\n",
    "spike_grad = surrogate.fast_sigmoid(slope=0.1)\n",
    "\n",
    "\n",
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden, bias=False)\n",
    "        # self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        # self.fc1.bias.data = torch.tensor(0.01)\n",
    "        self.fc1.weight.data = torch.ones(self.fc1.weight.size())\n",
    "        self.lif1 = snn.Leaky(\n",
    "            beta=hid_beta, threshold=hid_thresh, spike_grad=spike_grad\n",
    "        )\n",
    "        # self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        # self.fc2.bias.data = torch.tensor(0.01)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs, bias=False)\n",
    "        self.fc2.weight.data = torch.abs(self.fc2.weight.data)\n",
    "        self.lif2 = snn.Leaky(beta=out_beta, threshold=thresh, spike_grad=spike_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        # Also part of the first for debug\n",
    "        spk1_rec = []\n",
    "\n",
    "        num_steps = len(x)\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x[step])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "            spk1_rec.append(spk1)\n",
    "\n",
    "        return (\n",
    "            torch.stack(spk2_rec, dim=0),\n",
    "            torch.stack(mem2_rec, dim=0),\n",
    "            torch.stack(spk1_rec, dim=0),\n",
    "        )\n",
    "\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \t Train Loss: 147.03089904785156\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 1 \t Train Loss: 144.0891876220703\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 2 \t Train Loss: 141.09060668945312\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 3 \t Train Loss: 138.47914123535156\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 4 \t Train Loss: 136.00193786621094\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 5 \t Train Loss: 133.68653869628906\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 6 \t Train Loss: 131.67300415039062\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 7 \t Train Loss: 129.77171325683594\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 8 \t Train Loss: 128.14520263671875\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 9 \t Train Loss: 126.49054718017578\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 10 \t Train Loss: 125.03790283203125\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 11 \t Train Loss: 123.8633804321289\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 12 \t Train Loss: 122.66452026367188\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 13 \t Train Loss: 121.66311645507812\n",
      "Train set accuracy: 0.6904761791229248\n",
      "Iteration: 14 \t Train Loss: 120.87187957763672\n",
      "Train set accuracy: 0.6904761791229248\n",
      "Iteration: 15 \t Train Loss: 119.9972915649414\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 16 \t Train Loss: 119.33931732177734\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 17 \t Train Loss: 118.55250549316406\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 18 \t Train Loss: 117.79949951171875\n",
      "Train set accuracy: 0.6904761791229248\n",
      "Iteration: 19 \t Train Loss: 117.21690368652344\n",
      "Train set accuracy: 0.6904761791229248\n",
      "Iteration: 20 \t Train Loss: 116.61412811279297\n",
      "Train set accuracy: 0.6904761791229248\n",
      "Iteration: 21 \t Train Loss: 115.98313903808594\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 22 \t Train Loss: 115.45292663574219\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 23 \t Train Loss: 114.8719253540039\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 24 \t Train Loss: 114.39142608642578\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 25 \t Train Loss: 113.85722351074219\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 26 \t Train Loss: 113.3833236694336\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 27 \t Train Loss: 112.92088317871094\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 28 \t Train Loss: 112.32056427001953\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 29 \t Train Loss: 111.85673522949219\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 30 \t Train Loss: 111.31802368164062\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 31 \t Train Loss: 110.91720581054688\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 32 \t Train Loss: 110.39845275878906\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 33 \t Train Loss: 109.98238372802734\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 34 \t Train Loss: 109.42095184326172\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 35 \t Train Loss: 108.8759536743164\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 36 \t Train Loss: 108.45654296875\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 37 \t Train Loss: 108.04232025146484\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 38 \t Train Loss: 107.5599365234375\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 39 \t Train Loss: 107.15875244140625\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 40 \t Train Loss: 106.67163848876953\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 41 \t Train Loss: 106.34297180175781\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 42 \t Train Loss: 105.99815368652344\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 43 \t Train Loss: 105.67754364013672\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 44 \t Train Loss: 105.41509246826172\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 45 \t Train Loss: 105.09480285644531\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 46 \t Train Loss: 104.82770538330078\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 47 \t Train Loss: 104.57630157470703\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 48 \t Train Loss: 104.4094009399414\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 49 \t Train Loss: 104.26502990722656\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 50 \t Train Loss: 104.10252380371094\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 51 \t Train Loss: 103.96353149414062\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 52 \t Train Loss: 103.88871002197266\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 53 \t Train Loss: 103.87874603271484\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 54 \t Train Loss: 103.79620361328125\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 55 \t Train Loss: 103.756591796875\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 56 \t Train Loss: 103.73711395263672\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 57 \t Train Loss: 103.66747283935547\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 58 \t Train Loss: 103.61126708984375\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 59 \t Train Loss: 103.63604736328125\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 60 \t Train Loss: 103.67737579345703\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 61 \t Train Loss: 103.7197265625\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 62 \t Train Loss: 103.6980209350586\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 63 \t Train Loss: 103.69808959960938\n",
      "Train set accuracy: 0.5714285969734192\n",
      "Iteration: 64 \t Train Loss: 103.66238403320312\n",
      "Train set accuracy: 0.5714285969734192\n",
      "Iteration: 65 \t Train Loss: 103.74237060546875\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 66 \t Train Loss: 103.70315551757812\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 67 \t Train Loss: 103.73475646972656\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 68 \t Train Loss: 103.6930923461914\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 69 \t Train Loss: 103.71192932128906\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 70 \t Train Loss: 103.6944351196289\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 71 \t Train Loss: 103.61105346679688\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 72 \t Train Loss: 103.54000854492188\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 73 \t Train Loss: 103.49322509765625\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 74 \t Train Loss: 103.37429809570312\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 75 \t Train Loss: 103.28629302978516\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 76 \t Train Loss: 103.21353149414062\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 77 \t Train Loss: 103.14327239990234\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 78 \t Train Loss: 103.04759216308594\n",
      "Train set accuracy: 0.5714285969734192\n",
      "Iteration: 79 \t Train Loss: 102.93365478515625\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 80 \t Train Loss: 102.85684967041016\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 81 \t Train Loss: 102.8260498046875\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 82 \t Train Loss: 102.77179718017578\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 83 \t Train Loss: 102.75872039794922\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 84 \t Train Loss: 102.63629150390625\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 85 \t Train Loss: 102.59209442138672\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 86 \t Train Loss: 102.48211669921875\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 87 \t Train Loss: 102.46356964111328\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 88 \t Train Loss: 102.418701171875\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 89 \t Train Loss: 102.40113830566406\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 90 \t Train Loss: 102.3948745727539\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 91 \t Train Loss: 102.40170288085938\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 92 \t Train Loss: 102.41034698486328\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 93 \t Train Loss: 102.34468078613281\n",
      "Train set accuracy: 0.5952380895614624\n",
      "Iteration: 94 \t Train Loss: 102.28679656982422\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 95 \t Train Loss: 102.24842834472656\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 96 \t Train Loss: 102.24888610839844\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 97 \t Train Loss: 102.21304321289062\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 98 \t Train Loss: 102.15050506591797\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 99 \t Train Loss: 102.08831787109375\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 100 \t Train Loss: 102.06570434570312\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 101 \t Train Loss: 102.00086212158203\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 102 \t Train Loss: 101.99873352050781\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 103 \t Train Loss: 101.97217559814453\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 104 \t Train Loss: 101.86727905273438\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 105 \t Train Loss: 101.86880493164062\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 106 \t Train Loss: 101.76092529296875\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 107 \t Train Loss: 101.7637710571289\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 108 \t Train Loss: 101.69874572753906\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 109 \t Train Loss: 101.64723205566406\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 110 \t Train Loss: 101.6144027709961\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 111 \t Train Loss: 101.62911987304688\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 112 \t Train Loss: 101.59211730957031\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 113 \t Train Loss: 101.52220153808594\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 114 \t Train Loss: 101.49417877197266\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 115 \t Train Loss: 101.48067474365234\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 116 \t Train Loss: 101.43620300292969\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 117 \t Train Loss: 101.39871978759766\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 118 \t Train Loss: 101.38245391845703\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 119 \t Train Loss: 101.34170532226562\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 120 \t Train Loss: 101.34947204589844\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 121 \t Train Loss: 101.32556915283203\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 122 \t Train Loss: 101.26604461669922\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 123 \t Train Loss: 101.18698120117188\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 124 \t Train Loss: 101.09088897705078\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 125 \t Train Loss: 101.09048461914062\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 126 \t Train Loss: 101.07131958007812\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 127 \t Train Loss: 101.0566635131836\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 128 \t Train Loss: 101.0158462524414\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 129 \t Train Loss: 100.99109649658203\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 130 \t Train Loss: 100.97425079345703\n",
      "Train set accuracy: 0.6190476417541504\n",
      "Iteration: 131 \t Train Loss: 100.86927795410156\n",
      "Train set accuracy: 0.6428571343421936\n",
      "Iteration: 132 \t Train Loss: 100.80349731445312\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 133 \t Train Loss: 100.67395782470703\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 134 \t Train Loss: 100.64506530761719\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 135 \t Train Loss: 100.64257049560547\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 136 \t Train Loss: 100.59536743164062\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 137 \t Train Loss: 100.58849334716797\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 138 \t Train Loss: 100.52124786376953\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 139 \t Train Loss: 100.50659942626953\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 140 \t Train Loss: 100.38088989257812\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 141 \t Train Loss: 100.37451934814453\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 142 \t Train Loss: 100.35823059082031\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 143 \t Train Loss: 100.24515533447266\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 144 \t Train Loss: 100.20915985107422\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 145 \t Train Loss: 100.11104583740234\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 146 \t Train Loss: 100.0718994140625\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 147 \t Train Loss: 100.07698059082031\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 148 \t Train Loss: 100.01341247558594\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 149 \t Train Loss: 99.98243713378906\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 150 \t Train Loss: 99.94477081298828\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 151 \t Train Loss: 99.8641586303711\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 152 \t Train Loss: 99.87010192871094\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 153 \t Train Loss: 99.79329681396484\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 154 \t Train Loss: 99.72215270996094\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 155 \t Train Loss: 99.70712280273438\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 156 \t Train Loss: 99.60716247558594\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 157 \t Train Loss: 99.57404327392578\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 158 \t Train Loss: 99.41825103759766\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 159 \t Train Loss: 99.30245208740234\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 160 \t Train Loss: 99.32325744628906\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 161 \t Train Loss: 99.14356994628906\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 162 \t Train Loss: 99.07833862304688\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 163 \t Train Loss: 98.97357177734375\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 164 \t Train Loss: 98.89775848388672\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 165 \t Train Loss: 98.8635025024414\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 166 \t Train Loss: 98.66836547851562\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 167 \t Train Loss: 98.61170196533203\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 168 \t Train Loss: 98.62156677246094\n",
      "Train set accuracy: 0.6904761791229248\n",
      "Iteration: 169 \t Train Loss: 98.52132415771484\n",
      "Train set accuracy: 0.6666666865348816\n",
      "Iteration: 170 \t Train Loss: 98.37632751464844\n",
      "Train set accuracy: 0.7142857313156128\n",
      "Iteration: 171 \t Train Loss: 98.22933959960938\n",
      "Train set accuracy: 0.738095223903656\n",
      "Iteration: 172 \t Train Loss: 98.11274719238281\n",
      "Train set accuracy: 0.738095223903656\n",
      "Iteration: 173 \t Train Loss: 98.01432800292969\n",
      "Train set accuracy: 0.738095223903656\n",
      "Iteration: 174 \t Train Loss: 97.92422485351562\n",
      "Train set accuracy: 0.761904776096344\n",
      "Iteration: 175 \t Train Loss: 97.92240142822266\n",
      "Train set accuracy: 0.738095223903656\n",
      "Iteration: 176 \t Train Loss: 97.76940155029297\n",
      "Train set accuracy: 0.761904776096344\n",
      "Iteration: 177 \t Train Loss: 97.66132354736328\n",
      "Train set accuracy: 0.738095223903656\n",
      "Iteration: 178 \t Train Loss: 97.6063461303711\n",
      "Train set accuracy: 0.738095223903656\n",
      "Iteration: 179 \t Train Loss: 97.46168518066406\n",
      "Train set accuracy: 0.761904776096344\n",
      "Iteration: 180 \t Train Loss: 97.4078140258789\n",
      "Train set accuracy: 0.761904776096344\n",
      "Iteration: 181 \t Train Loss: 97.33220672607422\n",
      "Train set accuracy: 0.8095238208770752\n",
      "Iteration: 182 \t Train Loss: 97.19537353515625\n",
      "Train set accuracy: 0.8095238208770752\n",
      "Iteration: 183 \t Train Loss: 97.1455307006836\n",
      "Train set accuracy: 0.8095238208770752\n",
      "Iteration: 184 \t Train Loss: 97.07795715332031\n",
      "Train set accuracy: 0.8333333730697632\n",
      "Iteration: 185 \t Train Loss: 96.99365234375\n",
      "Train set accuracy: 0.8333333730697632\n",
      "Iteration: 186 \t Train Loss: 96.99747467041016\n",
      "Train set accuracy: 0.8333333730697632\n",
      "Iteration: 187 \t Train Loss: 96.83943176269531\n",
      "Train set accuracy: 0.8809524178504944\n",
      "Iteration: 188 \t Train Loss: 96.77482604980469\n",
      "Train set accuracy: 0.9047619104385376\n",
      "Iteration: 189 \t Train Loss: 96.66929626464844\n",
      "Train set accuracy: 0.9047619104385376\n",
      "Iteration: 190 \t Train Loss: 96.6181411743164\n",
      "Train set accuracy: 0.9047619104385376\n",
      "Iteration: 191 \t Train Loss: 96.48881530761719\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 192 \t Train Loss: 96.39229583740234\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 193 \t Train Loss: 96.31482696533203\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 194 \t Train Loss: 96.28465270996094\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 195 \t Train Loss: 96.20555114746094\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 196 \t Train Loss: 96.08781433105469\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 197 \t Train Loss: 95.99469757080078\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 198 \t Train Loss: 95.86507415771484\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 199 \t Train Loss: 95.80197143554688\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 200 \t Train Loss: 95.59002685546875\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 201 \t Train Loss: 95.53136444091797\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 202 \t Train Loss: 95.47274780273438\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 203 \t Train Loss: 95.37931823730469\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 204 \t Train Loss: 95.315673828125\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 205 \t Train Loss: 95.24634552001953\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 206 \t Train Loss: 95.19368743896484\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 207 \t Train Loss: 95.03079223632812\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 208 \t Train Loss: 94.9661636352539\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 209 \t Train Loss: 94.93026733398438\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 210 \t Train Loss: 94.90203094482422\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 211 \t Train Loss: 94.86772155761719\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 212 \t Train Loss: 94.83133697509766\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 213 \t Train Loss: 94.8250732421875\n",
      "Train set accuracy: 0.9285714626312256\n",
      "Iteration: 214 \t Train Loss: 94.71710205078125\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 215 \t Train Loss: 94.720703125\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 216 \t Train Loss: 94.65444946289062\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 217 \t Train Loss: 94.71553039550781\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 218 \t Train Loss: 94.66059875488281\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 219 \t Train Loss: 94.65411376953125\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 220 \t Train Loss: 94.57086181640625\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 221 \t Train Loss: 94.59080505371094\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 222 \t Train Loss: 94.50814056396484\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 223 \t Train Loss: 94.45604705810547\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 224 \t Train Loss: 94.45340728759766\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 225 \t Train Loss: 94.54689025878906\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 226 \t Train Loss: 94.54985046386719\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 227 \t Train Loss: 94.4931640625\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 228 \t Train Loss: 94.43423461914062\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 229 \t Train Loss: 94.44136810302734\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 230 \t Train Loss: 94.40730285644531\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 231 \t Train Loss: 94.26691436767578\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 232 \t Train Loss: 94.2443618774414\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 233 \t Train Loss: 94.17546081542969\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 234 \t Train Loss: 94.06656646728516\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 235 \t Train Loss: 94.00222778320312\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 236 \t Train Loss: 93.95250701904297\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 237 \t Train Loss: 93.84505462646484\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 238 \t Train Loss: 93.8482437133789\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 239 \t Train Loss: 93.81365203857422\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 240 \t Train Loss: 93.79389953613281\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 241 \t Train Loss: 93.78820037841797\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 242 \t Train Loss: 93.72181701660156\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 243 \t Train Loss: 93.66199493408203\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 244 \t Train Loss: 93.66757202148438\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 245 \t Train Loss: 93.63292694091797\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 246 \t Train Loss: 93.63599395751953\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 247 \t Train Loss: 93.60773468017578\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 248 \t Train Loss: 93.655029296875\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 249 \t Train Loss: 93.52880096435547\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 250 \t Train Loss: 93.47279357910156\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 251 \t Train Loss: 93.52395629882812\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 252 \t Train Loss: 93.54597473144531\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 253 \t Train Loss: 93.49629974365234\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 254 \t Train Loss: 93.51107025146484\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 255 \t Train Loss: 93.47721099853516\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 256 \t Train Loss: 93.48388671875\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 257 \t Train Loss: 93.49478149414062\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 258 \t Train Loss: 93.47579956054688\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 259 \t Train Loss: 93.56431579589844\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 260 \t Train Loss: 93.59827423095703\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 261 \t Train Loss: 93.54290008544922\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 262 \t Train Loss: 93.55162048339844\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 263 \t Train Loss: 93.53620910644531\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 264 \t Train Loss: 93.5504379272461\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 265 \t Train Loss: 93.54693603515625\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 266 \t Train Loss: 93.54105377197266\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 267 \t Train Loss: 93.5421371459961\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 268 \t Train Loss: 93.5862808227539\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 269 \t Train Loss: 93.58857727050781\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 270 \t Train Loss: 93.57292938232422\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 271 \t Train Loss: 93.53824615478516\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 272 \t Train Loss: 93.52754211425781\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 273 \t Train Loss: 93.51954650878906\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 274 \t Train Loss: 93.51822662353516\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 275 \t Train Loss: 93.52790832519531\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 276 \t Train Loss: 93.58674621582031\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 277 \t Train Loss: 93.52054595947266\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 278 \t Train Loss: 93.60952758789062\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 279 \t Train Loss: 93.66888427734375\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 280 \t Train Loss: 93.60722351074219\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 281 \t Train Loss: 93.61927032470703\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 282 \t Train Loss: 93.64151763916016\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 283 \t Train Loss: 93.67556762695312\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 284 \t Train Loss: 93.68209838867188\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 285 \t Train Loss: 93.69522857666016\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 286 \t Train Loss: 93.70220947265625\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 287 \t Train Loss: 93.70849609375\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 288 \t Train Loss: 93.6520767211914\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 289 \t Train Loss: 93.67012023925781\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 290 \t Train Loss: 93.66107177734375\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 291 \t Train Loss: 93.66020965576172\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 292 \t Train Loss: 93.71438598632812\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 293 \t Train Loss: 93.65727996826172\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 294 \t Train Loss: 93.6319351196289\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 295 \t Train Loss: 93.71141052246094\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 296 \t Train Loss: 93.7198257446289\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 297 \t Train Loss: 93.6593246459961\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 298 \t Train Loss: 93.69869995117188\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 299 \t Train Loss: 93.61690521240234\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 300 \t Train Loss: 93.58184814453125\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 301 \t Train Loss: 93.6329345703125\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 302 \t Train Loss: 93.60504150390625\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 303 \t Train Loss: 93.53424835205078\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 304 \t Train Loss: 93.49557495117188\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 305 \t Train Loss: 93.59369659423828\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 306 \t Train Loss: 93.62311553955078\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 307 \t Train Loss: 93.63420867919922\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 308 \t Train Loss: 93.58361053466797\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 309 \t Train Loss: 93.5137939453125\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 310 \t Train Loss: 93.55793762207031\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 311 \t Train Loss: 93.53756713867188\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 312 \t Train Loss: 93.5404052734375\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 313 \t Train Loss: 93.5405044555664\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 314 \t Train Loss: 93.63350677490234\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 315 \t Train Loss: 93.66482543945312\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 316 \t Train Loss: 93.67330169677734\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 317 \t Train Loss: 93.78804779052734\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 318 \t Train Loss: 93.82161712646484\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 319 \t Train Loss: 93.8043441772461\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 320 \t Train Loss: 93.7655029296875\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 321 \t Train Loss: 93.74707794189453\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 322 \t Train Loss: 93.74424743652344\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 323 \t Train Loss: 93.87429809570312\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 324 \t Train Loss: 93.91424560546875\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 325 \t Train Loss: 93.90332794189453\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 326 \t Train Loss: 93.96929168701172\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 327 \t Train Loss: 94.02069854736328\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 328 \t Train Loss: 94.10581970214844\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 329 \t Train Loss: 94.0678482055664\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 330 \t Train Loss: 94.23666381835938\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 331 \t Train Loss: 94.30436706542969\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 332 \t Train Loss: 94.34315490722656\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 333 \t Train Loss: 94.44015502929688\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 334 \t Train Loss: 94.49031829833984\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 335 \t Train Loss: 94.63127136230469\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 336 \t Train Loss: 94.61665344238281\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 337 \t Train Loss: 94.68032836914062\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 338 \t Train Loss: 94.69688415527344\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 339 \t Train Loss: 94.76570892333984\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 340 \t Train Loss: 94.73211669921875\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 341 \t Train Loss: 94.72386932373047\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 342 \t Train Loss: 94.78784942626953\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 343 \t Train Loss: 94.7503433227539\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 344 \t Train Loss: 94.8530044555664\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 345 \t Train Loss: 94.83586120605469\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 346 \t Train Loss: 94.83744812011719\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 347 \t Train Loss: 94.94417572021484\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 348 \t Train Loss: 95.00425720214844\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 349 \t Train Loss: 95.13712310791016\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 350 \t Train Loss: 95.1550521850586\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 351 \t Train Loss: 95.27592468261719\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 352 \t Train Loss: 95.28311157226562\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 353 \t Train Loss: 95.31562042236328\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 354 \t Train Loss: 95.36832427978516\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 355 \t Train Loss: 95.51435089111328\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 356 \t Train Loss: 95.53242492675781\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 357 \t Train Loss: 95.59129333496094\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 358 \t Train Loss: 95.55976867675781\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 359 \t Train Loss: 95.5572280883789\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 360 \t Train Loss: 95.50440979003906\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 361 \t Train Loss: 95.56175231933594\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 362 \t Train Loss: 95.49916076660156\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 363 \t Train Loss: 95.52022552490234\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 364 \t Train Loss: 95.55870819091797\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 365 \t Train Loss: 95.58029174804688\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 366 \t Train Loss: 95.4681625366211\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 367 \t Train Loss: 95.3776626586914\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 368 \t Train Loss: 95.33293151855469\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 369 \t Train Loss: 95.2804946899414\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 370 \t Train Loss: 95.31599426269531\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 371 \t Train Loss: 95.27950286865234\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 372 \t Train Loss: 95.2934799194336\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 373 \t Train Loss: 95.23152923583984\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 374 \t Train Loss: 95.24125671386719\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 375 \t Train Loss: 95.2263412475586\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 376 \t Train Loss: 95.10569763183594\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 377 \t Train Loss: 95.08642578125\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 378 \t Train Loss: 95.01261138916016\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 379 \t Train Loss: 94.96121978759766\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 380 \t Train Loss: 94.85574340820312\n",
      "Train set accuracy: 0.9523809552192688\n",
      "Iteration: 381 \t Train Loss: 94.7190933227539\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 382 \t Train Loss: 94.66461181640625\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 383 \t Train Loss: 94.67227172851562\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 384 \t Train Loss: 94.59124755859375\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 385 \t Train Loss: 94.4333267211914\n",
      "Train set accuracy: 0.9761905074119568\n",
      "Iteration: 386 \t Train Loss: 94.3214340209961\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 387 \t Train Loss: 94.15767669677734\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 388 \t Train Loss: 94.16268157958984\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 389 \t Train Loss: 94.06427001953125\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 390 \t Train Loss: 94.00489044189453\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 391 \t Train Loss: 94.04573059082031\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 392 \t Train Loss: 93.98636627197266\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 393 \t Train Loss: 93.87429809570312\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 394 \t Train Loss: 93.80792999267578\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 395 \t Train Loss: 93.8132095336914\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 396 \t Train Loss: 93.6588134765625\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 397 \t Train Loss: 93.70091247558594\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 398 \t Train Loss: 93.60040283203125\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 399 \t Train Loss: 93.5050048828125\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 400 \t Train Loss: 93.49620819091797\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 401 \t Train Loss: 93.57232666015625\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 402 \t Train Loss: 93.46205139160156\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 403 \t Train Loss: 93.48445129394531\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 404 \t Train Loss: 93.3989028930664\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 405 \t Train Loss: 93.30876922607422\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 406 \t Train Loss: 93.10209655761719\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 407 \t Train Loss: 93.10977172851562\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 408 \t Train Loss: 92.91492462158203\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 409 \t Train Loss: 92.90447998046875\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 410 \t Train Loss: 92.75470733642578\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 411 \t Train Loss: 92.65673065185547\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 412 \t Train Loss: 92.59783935546875\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 413 \t Train Loss: 92.5726547241211\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 414 \t Train Loss: 92.48454284667969\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 415 \t Train Loss: 92.43026733398438\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 416 \t Train Loss: 92.37736511230469\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 417 \t Train Loss: 92.38815307617188\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 418 \t Train Loss: 92.34745025634766\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 419 \t Train Loss: 92.26665496826172\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 420 \t Train Loss: 92.2154312133789\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 421 \t Train Loss: 92.22747039794922\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 422 \t Train Loss: 92.14616394042969\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 423 \t Train Loss: 92.15904235839844\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 424 \t Train Loss: 92.0602798461914\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 425 \t Train Loss: 91.9832534790039\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 426 \t Train Loss: 91.92950439453125\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 427 \t Train Loss: 91.90335083007812\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 428 \t Train Loss: 91.87993621826172\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 429 \t Train Loss: 91.8367919921875\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 430 \t Train Loss: 91.73186492919922\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 431 \t Train Loss: 91.70512390136719\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 432 \t Train Loss: 91.65499877929688\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 433 \t Train Loss: 91.50342559814453\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 434 \t Train Loss: 91.55634307861328\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 435 \t Train Loss: 91.48506927490234\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 436 \t Train Loss: 91.43018341064453\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 437 \t Train Loss: 91.38407135009766\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 438 \t Train Loss: 91.33936309814453\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 439 \t Train Loss: 91.2641372680664\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 440 \t Train Loss: 91.26375579833984\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 441 \t Train Loss: 91.25315856933594\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 442 \t Train Loss: 91.21334838867188\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 443 \t Train Loss: 91.25297546386719\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 444 \t Train Loss: 91.2300033569336\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 445 \t Train Loss: 91.2411117553711\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 446 \t Train Loss: 91.17423248291016\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 447 \t Train Loss: 91.18273162841797\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 448 \t Train Loss: 91.24183654785156\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 449 \t Train Loss: 91.21236419677734\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 450 \t Train Loss: 91.18965911865234\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 451 \t Train Loss: 91.16996002197266\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 452 \t Train Loss: 91.2761001586914\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 453 \t Train Loss: 91.18020629882812\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 454 \t Train Loss: 91.06959533691406\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 455 \t Train Loss: 91.02127838134766\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 456 \t Train Loss: 90.93048095703125\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 457 \t Train Loss: 90.9267578125\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 458 \t Train Loss: 90.89688873291016\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 459 \t Train Loss: 90.87765502929688\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 460 \t Train Loss: 90.83588409423828\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 461 \t Train Loss: 90.9533462524414\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 462 \t Train Loss: 90.92793273925781\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 463 \t Train Loss: 90.8979263305664\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 464 \t Train Loss: 90.81749725341797\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 465 \t Train Loss: 90.83241271972656\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 466 \t Train Loss: 90.87952423095703\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 467 \t Train Loss: 90.93229675292969\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 468 \t Train Loss: 90.88372039794922\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 469 \t Train Loss: 90.87666320800781\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 470 \t Train Loss: 90.84193420410156\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 471 \t Train Loss: 90.80905151367188\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 472 \t Train Loss: 90.73187255859375\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 473 \t Train Loss: 90.72572326660156\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 474 \t Train Loss: 90.69845581054688\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 475 \t Train Loss: 90.68156433105469\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 476 \t Train Loss: 90.7146224975586\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 477 \t Train Loss: 90.77318572998047\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 478 \t Train Loss: 90.7831802368164\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 479 \t Train Loss: 90.79615020751953\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 480 \t Train Loss: 90.81806945800781\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 481 \t Train Loss: 90.73783874511719\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 482 \t Train Loss: 90.7503662109375\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 483 \t Train Loss: 90.80018615722656\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 484 \t Train Loss: 90.84068298339844\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 485 \t Train Loss: 90.82756805419922\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 486 \t Train Loss: 90.76637268066406\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 487 \t Train Loss: 90.81936645507812\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 488 \t Train Loss: 90.82262420654297\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 489 \t Train Loss: 90.85975646972656\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 490 \t Train Loss: 90.93655395507812\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 491 \t Train Loss: 90.81600189208984\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 492 \t Train Loss: 90.7839584350586\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 493 \t Train Loss: 90.74647521972656\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 494 \t Train Loss: 90.69730377197266\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 495 \t Train Loss: 90.66580200195312\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 496 \t Train Loss: 90.69287109375\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 497 \t Train Loss: 90.71739959716797\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 498 \t Train Loss: 90.6795425415039\n",
      "Train set accuracy: 1.0\n",
      "Iteration: 499 \t Train Loss: 90.69868469238281\n",
      "Train set accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "loss = SF.mse_count_loss(correct_rate=0.75, incorrect_rate=0.25)\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 500\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "\n",
    "data = train_data.to(device)\n",
    "targets = train_labels.to(device)\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # forward pass\n",
    "    net.train()\n",
    "    spk_rec, _, spk_rec_hid = net(data)\n",
    "\n",
    "    # initialize the loss & sum over time\n",
    "    loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "    loss_val += loss(spk_rec, torch.argmax(targets, axis=1))\n",
    "\n",
    "    # Gradient calculation + weight update\n",
    "    optimizer.zero_grad()\n",
    "    loss_val.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Store loss history for future plotting\n",
    "    loss_hist.append(loss_val.item())\n",
    "\n",
    "    # Print train/test loss/accuracy\n",
    "    print(f\"Iteration: {epoch} \\t Train Loss: {loss_val.item()}\")\n",
    "    print(f\"Train set accuracy: {measure_accuracy(spk_rec, targets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1760,  0.2796,  0.3148,  0.2003,  0.0097,  0.2138,  0.2412,  0.2532,\n",
       "         -0.0379,  0.1707],\n",
       "        [ 0.2156,  0.2478,  0.4330,  0.4157,  0.4089,  0.3307,  0.3383,  0.4715,\n",
       "          0.7206,  0.7573]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc2.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "def measure_test_accuracy(model, test_data, test_targets):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        running_length = 0\n",
    "        running_accuracy = 0\n",
    "\n",
    "        data = test_data.to(device)\n",
    "        targets = test_targets.to(device)\n",
    "\n",
    "        # forward-pass\n",
    "        spk_rec, _, spk_rec_hid = model(data)\n",
    "        spike_count = spk_rec.sum(0)\n",
    "        _, max_spike = spike_count.max(1)\n",
    "\n",
    "        # correct classes for one batch\n",
    "        num_correct = (max_spike == torch.argmax(targets, axis=1)).sum()\n",
    "\n",
    "        # total accuracy\n",
    "        running_length += len(targets)\n",
    "        running_accuracy += num_correct\n",
    "\n",
    "        accuracy = running_accuracy / running_length\n",
    "\n",
    "        return accuracy.item()\n",
    "\n",
    "\n",
    "print(f\"Test Accuracy: {measure_test_accuracy(net, test_data, test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
